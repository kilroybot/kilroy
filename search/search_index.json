{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kilroy social bot \ud83e\udd16 About \ud83d\udd17 Kilroy is a framework for training bots to generate engaging social media posts. It uses reinforcement learning, as well as usual supervised learning, to steer bots posting on social media to generate content that is more likely to see big numbers. You can deploy your own instance of kilroy using any backbone model and train it on any social media platform. Quickstart \ud83d\udd17 Visit the example page and follow the steps to see kilroy in action and play with it yourself.","title":"Home"},{"location":"#about","text":"Kilroy is a framework for training bots to generate engaging social media posts. It uses reinforcement learning, as well as usual supervised learning, to steer bots posting on social media to generate content that is more likely to see big numbers. You can deploy your own instance of kilroy using any backbone model and train it on any social media platform.","title":"About"},{"location":"#quickstart","text":"Visit the example page and follow the steps to see kilroy in action and play with it yourself.","title":"Quickstart"},{"location":"architecture/","text":"Architecture \ud83d\udd17 Kilroy is divided into multiple parts, each with their own responsibilities. You can replace any of these parts with your own implementation, as long as it conforms to the API. Parts \ud83d\udd17 You can read more about each part in the following sections. Face \ud83d\udd17 The face is the part that is responsible for communicating with a social media platform. Think of it as a wrapper around the social media platform's API, that conforms to the kilroy API. There are default implementation for Discord and Twitter . You should write your own face if you want to use kilroy with a platform that is not supported by default. Module \ud83d\udd17 A module is a part responsible for handling all operations related to the model, like generating output and updating weights. Again, think of it as a wrapper around the model of your choice that conforms to the kilroy API. There is a default implementation for any models that are supported by HuggingFace . You should write your own module if you want to use kilroy with your own model. Controller \ud83d\udd17 The controller is the part that controls the training process using the face and the module. It also serves as a gateway to the system from outside (e.g. from the Web UI). The default implementation can be found here and should be sufficient for most use cases. But of course, you can write your own controller. gRPC-Web Proxy \ud83d\udd17 This parts enables the dashboard to communicate with the controller. You can find the implementation here . It should work as it is. Dashboard \ud83d\udd17 The dashboard is a web app that can be used to control the training process. Think about it as the easiest to use interface for the whole system. The default implementation can be found here . Communication \ud83d\udd17 The communication between the parts is done using gRPC. The gRPC definitions can be found here . You can use them to generate stubs that conform to the API for your own implementations in any language.","title":"Architecture"},{"location":"architecture/#architecture","text":"Kilroy is divided into multiple parts, each with their own responsibilities. You can replace any of these parts with your own implementation, as long as it conforms to the API.","title":"Architecture"},{"location":"architecture/#parts","text":"You can read more about each part in the following sections.","title":"Parts"},{"location":"architecture/#face","text":"The face is the part that is responsible for communicating with a social media platform. Think of it as a wrapper around the social media platform's API, that conforms to the kilroy API. There are default implementation for Discord and Twitter . You should write your own face if you want to use kilroy with a platform that is not supported by default.","title":"Face"},{"location":"architecture/#module","text":"A module is a part responsible for handling all operations related to the model, like generating output and updating weights. Again, think of it as a wrapper around the model of your choice that conforms to the kilroy API. There is a default implementation for any models that are supported by HuggingFace . You should write your own module if you want to use kilroy with your own model.","title":"Module"},{"location":"architecture/#controller","text":"The controller is the part that controls the training process using the face and the module. It also serves as a gateway to the system from outside (e.g. from the Web UI). The default implementation can be found here and should be sufficient for most use cases. But of course, you can write your own controller.","title":"Controller"},{"location":"architecture/#grpc-web-proxy","text":"This parts enables the dashboard to communicate with the controller. You can find the implementation here . It should work as it is.","title":"gRPC-Web Proxy"},{"location":"architecture/#dashboard","text":"The dashboard is a web app that can be used to control the training process. Think about it as the easiest to use interface for the whole system. The default implementation can be found here .","title":"Dashboard"},{"location":"architecture/#communication","text":"The communication between the parts is done using gRPC. The gRPC definitions can be found here . You can use them to generate stubs that conform to the API for your own implementations in any language.","title":"Communication"},{"location":"example/","text":"Example \ud83d\udd17 This example shows how to use kilroy to train a language model on some social media environment. It uses GPT-2 from HuggingFace as the language model and targets Discord as the environment. Prerequisites \ud83d\udd17 First, you need to get the necessary files. You can get them here . Then, you need to create a Discord bot and obtain its token. You can do it here . You also need to find two channels in some Discord server, one for user messages and one for bot messages. It can be the same channel, if you want it that way. Paste the bot token and channel IDs into appropriate entries in the .env file. You also need to install Docker and Docker Compose. You can get them here . Running \ud83d\udd17 To run the example, simply run the following command: docker-compose up This will start all the services. The web app will be available at http://localhost:14000 . Persistence \ud83d\udd17 This stack uses Docker volumes to persist data. The services save their state on exit and load it back on start.","title":"Example"},{"location":"example/#example","text":"This example shows how to use kilroy to train a language model on some social media environment. It uses GPT-2 from HuggingFace as the language model and targets Discord as the environment.","title":"Example"},{"location":"example/#prerequisites","text":"First, you need to get the necessary files. You can get them here . Then, you need to create a Discord bot and obtain its token. You can do it here . You also need to find two channels in some Discord server, one for user messages and one for bot messages. It can be the same channel, if you want it that way. Paste the bot token and channel IDs into appropriate entries in the .env file. You also need to install Docker and Docker Compose. You can get them here .","title":"Prerequisites"},{"location":"example/#running","text":"To run the example, simply run the following command: docker-compose up This will start all the services. The web app will be available at http://localhost:14000 .","title":"Running"},{"location":"example/#persistence","text":"This stack uses Docker volumes to persist data. The services save their state on exit and load it back on start.","title":"Persistence"},{"location":"how-it-works/","text":"How it works \ud83d\udd17 The goal is to be able to train a bot to generate social media posts that are the most likely to engage with the audience. How to achieve that? Posts \ud83d\udd17 Posts need to be \"understandable\" by the bot. It means that posts need to be mapped to the \"language\" of the bot. Fortunately, if we assume the posts are textual only, this is not a problem. Textual content can be simply seen as a sequence of tokens (words, punctuation, etc.) that are known to the bot. If we use sufficiently powerful language model (e.g. GPT-2 ), that supports techniques such as Byte-level Byte-Pair Encoding (BBPE) , then any text can be handled without any loss of information. Posts often contain other types of content, such as images, videos, etc. Kilroy doesn't support them by default. No default implementation of a module can handle them. However, all faces and the dashboard can handle posts with text and images, if you are able to create them in your module. So feel free to create your own module that can handle generating such posts. Model \ud83d\udd17 The bot is a model that consists of some parameters representing its knowledge. When talking about textual content, the model is a language model. It operates on a sequence of tokens from known vocabulary and predicts the probability of the next token in the sequence. This way you can generate a sequence of tokens that make up an entire post. One example of a family of such models is Transformers . And one example of a specific model is GPT-2 . Scores \ud83d\udd17 The bot needs to be able to evaluate the quality of a post. The score should be a single number that represents how good the post is. The higher the score, the better the post. You need to choose how you want your posts to be scored. For example, you can choose to maximize the number of likes, comments, views, impressions or some function of them. The goal is to achieve higher and higher scores over time. Training \ud83d\udd17 If we have a model that can generate something and a way to evaluate it, then we can train the model to generate better things. More specifically, we can use reinforcement learning techniques to train the model to make decisions that result in higher rewards. In our case, this means generating posts that see bigger numbers.","title":"How it works"},{"location":"how-it-works/#how-it-works","text":"The goal is to be able to train a bot to generate social media posts that are the most likely to engage with the audience. How to achieve that?","title":"How it works"},{"location":"how-it-works/#posts","text":"Posts need to be \"understandable\" by the bot. It means that posts need to be mapped to the \"language\" of the bot. Fortunately, if we assume the posts are textual only, this is not a problem. Textual content can be simply seen as a sequence of tokens (words, punctuation, etc.) that are known to the bot. If we use sufficiently powerful language model (e.g. GPT-2 ), that supports techniques such as Byte-level Byte-Pair Encoding (BBPE) , then any text can be handled without any loss of information. Posts often contain other types of content, such as images, videos, etc. Kilroy doesn't support them by default. No default implementation of a module can handle them. However, all faces and the dashboard can handle posts with text and images, if you are able to create them in your module. So feel free to create your own module that can handle generating such posts.","title":"Posts"},{"location":"how-it-works/#model","text":"The bot is a model that consists of some parameters representing its knowledge. When talking about textual content, the model is a language model. It operates on a sequence of tokens from known vocabulary and predicts the probability of the next token in the sequence. This way you can generate a sequence of tokens that make up an entire post. One example of a family of such models is Transformers . And one example of a specific model is GPT-2 .","title":"Model"},{"location":"how-it-works/#scores","text":"The bot needs to be able to evaluate the quality of a post. The score should be a single number that represents how good the post is. The higher the score, the better the post. You need to choose how you want your posts to be scored. For example, you can choose to maximize the number of likes, comments, views, impressions or some function of them. The goal is to achieve higher and higher scores over time.","title":"Scores"},{"location":"how-it-works/#training","text":"If we have a model that can generate something and a way to evaluate it, then we can train the model to generate better things. More specifically, we can use reinforcement learning techniques to train the model to make decisions that result in higher rewards. In our case, this means generating posts that see bigger numbers.","title":"Training"},{"location":"installation/","text":"Installation \ud83d\udd17 All Python packages for kilroy are available on PyPI . All executables for kilroy are available as Docker images on GitHub . You can use them to deploy kilroy the way you like (locally, on your server, in the cloud, etc.). If you want to deploy locally, then visit the example page to get started.","title":"Installation"},{"location":"installation/#installation","text":"All Python packages for kilroy are available on PyPI . All executables for kilroy are available as Docker images on GitHub . You can use them to deploy kilroy the way you like (locally, on your server, in the cloud, etc.). If you want to deploy locally, then visit the example page to get started.","title":"Installation"},{"location":"customization/faces/","text":"Faces \ud83d\udd17 If you want to use a social media platform that is not supported by default, you should implement your own face that conforms to the API. Then you can use it in the system without changing any other parts. There are default faces for Discord and Twitter . API \ud83d\udd17 All communication is done with gRPC. The gRPC definitions for a face can be found here . You can use them to generate stubs that conform to the API for your own implementation in any language. Packages \ud83d\udd17 If you want to write your implementation in Python, you can use kilroy-face-server-py-sdk to make it easier. It already implements a lot of the boilerplate code and provides a convenient interface that you just need to fill in with your logic.","title":"Faces"},{"location":"customization/faces/#faces","text":"If you want to use a social media platform that is not supported by default, you should implement your own face that conforms to the API. Then you can use it in the system without changing any other parts. There are default faces for Discord and Twitter .","title":"Faces"},{"location":"customization/faces/#api","text":"All communication is done with gRPC. The gRPC definitions for a face can be found here . You can use them to generate stubs that conform to the API for your own implementation in any language.","title":"API"},{"location":"customization/faces/#packages","text":"If you want to write your implementation in Python, you can use kilroy-face-server-py-sdk to make it easier. It already implements a lot of the boilerplate code and provides a convenient interface that you just need to fill in with your logic.","title":"Packages"},{"location":"customization/modules/","text":"Modules \ud83d\udd17 If you want to use a model that is not supported by default, you should implement your own module that conforms to the API. Then you can use it in the system without changing any other parts. There is a default implementation for any models that are supported by HuggingFace . API \ud83d\udd17 All communication is done with gRPC. The gRPC definitions for a module can be found here . You can use them to generate stubs that conform to the API for your own implementation in any language. Packages \ud83d\udd17 If you want to write your implementation in Python, you can use kilroy-module-server-py-sdk to make it easier. It already implements a lot of the boilerplate code and provides a convenient interface that you just need to fill in with your logic. Furthermore, if you want to use a PyTorch model, you can use kilroy-module-pytorch-py-sdk to make it even easier. It's provides boilerplate code to help working with PyTorch models.","title":"Modules"},{"location":"customization/modules/#modules","text":"If you want to use a model that is not supported by default, you should implement your own module that conforms to the API. Then you can use it in the system without changing any other parts. There is a default implementation for any models that are supported by HuggingFace .","title":"Modules"},{"location":"customization/modules/#api","text":"All communication is done with gRPC. The gRPC definitions for a module can be found here . You can use them to generate stubs that conform to the API for your own implementation in any language.","title":"API"},{"location":"customization/modules/#packages","text":"If you want to write your implementation in Python, you can use kilroy-module-server-py-sdk to make it easier. It already implements a lot of the boilerplate code and provides a convenient interface that you just need to fill in with your logic. Furthermore, if you want to use a PyTorch model, you can use kilroy-module-pytorch-py-sdk to make it even easier. It's provides boilerplate code to help working with PyTorch models.","title":"Packages"},{"location":"usage/configuration/","text":"Configuration \ud83d\udd17 The system is built in a way to allow you to change its configuration at runtime. All services need to define and expose a schema of their configuration. This schema is used to build a form in the dashboard that allows you to change the configuration of the service. Also, all the default implementations of services store their state on disk on exit, and load it back on startup. So you can get back to the same state after a restart.","title":"Configuration"},{"location":"usage/configuration/#configuration","text":"The system is built in a way to allow you to change its configuration at runtime. All services need to define and expose a schema of their configuration. This schema is used to build a form in the dashboard that allows you to change the configuration of the service. Also, all the default implementations of services store their state on disk on exit, and load it back on startup. So you can get back to the same state after a restart.","title":"Configuration"},{"location":"usage/dashboard/","text":"Dashboard \ud83d\udd17 The main way to interact with the system is through the dashboard. The dashboard is a web application that allows you to control the training process. It is accessible at http://localhost:14000 by default. Pages \ud83d\udd17 The dashboard has several pages described below. Home \ud83d\udd17 The home page shows the current status and metadata of all the components of the system. It also shows the current status of the training process and a simplified view of the metrics. Training \ud83d\udd17 The training page allows you to see and control the training process. Read more in the training page. Controller \ud83d\udd17 The controller page shows the configuration of the controller and allows you to modify it. Read more in the configuration page. Face \ud83d\udd17 The face page shows the configuration of the face and allows you to modify it. Read more in the configuration page. Module \ud83d\udd17 The module page shows the configuration of the module and allows you to modify it. Read more in the configuration page. Feed \ud83d\udd17 The feed page displays the latest posts, so that you can keep track of what, when and where has been posted. Playground \ud83d\udd17 The playground page allows you to generate posts without actually posting them. This way you can see what the model is capable of generating at any given time.","title":"Dashboard"},{"location":"usage/dashboard/#dashboard","text":"The main way to interact with the system is through the dashboard. The dashboard is a web application that allows you to control the training process. It is accessible at http://localhost:14000 by default.","title":"Dashboard"},{"location":"usage/dashboard/#pages","text":"The dashboard has several pages described below.","title":"Pages"},{"location":"usage/dashboard/#home","text":"The home page shows the current status and metadata of all the components of the system. It also shows the current status of the training process and a simplified view of the metrics.","title":"Home"},{"location":"usage/dashboard/#training","text":"The training page allows you to see and control the training process. Read more in the training page.","title":"Training"},{"location":"usage/dashboard/#controller","text":"The controller page shows the configuration of the controller and allows you to modify it. Read more in the configuration page.","title":"Controller"},{"location":"usage/dashboard/#face","text":"The face page shows the configuration of the face and allows you to modify it. Read more in the configuration page.","title":"Face"},{"location":"usage/dashboard/#module","text":"The module page shows the configuration of the module and allows you to modify it. Read more in the configuration page.","title":"Module"},{"location":"usage/dashboard/#feed","text":"The feed page displays the latest posts, so that you can keep track of what, when and where has been posted.","title":"Feed"},{"location":"usage/dashboard/#playground","text":"The playground page allows you to generate posts without actually posting them. This way you can see what the model is capable of generating at any given time.","title":"Playground"},{"location":"usage/training/","text":"Training \ud83d\udd17 Training is at the core of the system. And you should be always training, as peoples reactions change over time. Modes \ud83d\udd17 There are two modes of training, each covering a different use case. For optimal performance, you should alternate between both modes. Offline \ud83d\udd17 Offline mode enables you to train your model on a dataset of past posts. This is useful to make your model used to a specific style of internet language. In most cases, you will be using some model pretrained on a large dataset of articles written in formal English. Then it's a good idea to adjust the model so that it's able to \"speak\" in a way more similar to the language used on a social media channel where you want to use it. It uses simple supervised learning. This process is pretty straightforward and should almost always result in convergence with the proper parameters. But watch out for overfitting, as it's easy to do. Generally, you want your model to generate text that is only stylistically similar to the existing posts and not to copy them. The face is responsible for defining where exactly the existing posts are coming from. Online \ud83d\udd17 Online mode works by constantly generating new posts, posting them and then using the reactions to the posts as feedback to improve the model. It uses reinforcement learning. This is the most powerful mode, as it allows you to train your model to generate posts that are actually liked by the audience. But it's also the most difficult to use, as it requires a lot of tuning and experimentation. It's also the most time-consuming, as you need to wait for the reactions from people to come in, and you can't post too often, as it will only annoy and distract your audience. The controller is responsible for scheduling the generation of new posts and the evaluation of the reactions to the posts. Dashboard \ud83d\udd17 You can monitor and control the training process in the dashboard. There is a quick view of the training status and a detailed view of all the metrics. You can control the training process by starting and stopping it.","title":"Training"},{"location":"usage/training/#training","text":"Training is at the core of the system. And you should be always training, as peoples reactions change over time.","title":"Training"},{"location":"usage/training/#modes","text":"There are two modes of training, each covering a different use case. For optimal performance, you should alternate between both modes.","title":"Modes"},{"location":"usage/training/#offline","text":"Offline mode enables you to train your model on a dataset of past posts. This is useful to make your model used to a specific style of internet language. In most cases, you will be using some model pretrained on a large dataset of articles written in formal English. Then it's a good idea to adjust the model so that it's able to \"speak\" in a way more similar to the language used on a social media channel where you want to use it. It uses simple supervised learning. This process is pretty straightforward and should almost always result in convergence with the proper parameters. But watch out for overfitting, as it's easy to do. Generally, you want your model to generate text that is only stylistically similar to the existing posts and not to copy them. The face is responsible for defining where exactly the existing posts are coming from.","title":"Offline"},{"location":"usage/training/#online","text":"Online mode works by constantly generating new posts, posting them and then using the reactions to the posts as feedback to improve the model. It uses reinforcement learning. This is the most powerful mode, as it allows you to train your model to generate posts that are actually liked by the audience. But it's also the most difficult to use, as it requires a lot of tuning and experimentation. It's also the most time-consuming, as you need to wait for the reactions from people to come in, and you can't post too often, as it will only annoy and distract your audience. The controller is responsible for scheduling the generation of new posts and the evaluation of the reactions to the posts.","title":"Online"},{"location":"usage/training/#dashboard","text":"You can monitor and control the training process in the dashboard. There is a quick view of the training status and a detailed view of all the metrics. You can control the training process by starting and stopping it.","title":"Dashboard"}]}